# Log Service â€” Event-Driven Microservice with Kafka & MongoDB

This project is a **scalable event-driven microservice** built with **Node.js, Express, Kafka, and MongoDB**.  
It processes **user activity logs** in real time using Kafka, persists them into MongoDB, and exposes a REST API to query the logs with pagination and filtering.

---

## ğŸ§± Architecture Overview

The system follows a **clean / layered architecture inspired by DDD**:

- **Presentation Layer (API Layer)**  
  - `Express` routes and controllers  
  - Validates HTTP requests and returns HTTP responses

- **Application Layer (Services)**  
  - Contains the main business use cases  
  - Orchestrates between repositories and Kafka producers/consumers

- **Domain Layer**  
  - `UserLog` Mongoose model and domain rules around logs

- **Infrastructure Layer**  
  - MongoDB connection (`mongoose`)  
  - Kafka producer & consumer (using `kafkajs`)  
  - Repositories that talk to the database

### Data Flow (Happy Path)

1. Client sends `POST /log/create` with log data.
2. API validates the payload and saves the log immediately in MongoDB.
3. The same log is produced to Kafka topic **`user-logs`**.
4. Kafka consumer listens to `user-logs`, processes the message, and (optionally) enriches or re-saves the log.
5. Client can query processed logs using `GET /log` with pagination & filters.

---

## ğŸ›  Tech Stack

- **Language:** Node.js (ESM)
- **Framework:** Express
- **Messaging:** Apache Kafka (via `kafkajs`)
- **Database:** MongoDB + Mongoose
- **Containerization:** Docker & Docker Compose
- **Orchestration:** Kubernetes (K8s) on Minikube
- **Other:**
  - Logging using `console` (can be extended to `winston`)
  - Environment variables via `.env`

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ k8s/                      # Kubernetes manifests (Deployments & Services)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ mongo.js          # MongoDB connection
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â””â”€â”€ userLog.model.js
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”œâ”€â”€ kafka/
â”‚   â”‚   â”‚   â”œâ”€â”€ producer.kafka.js
â”‚   â”‚   â”‚   â””â”€â”€ consumer.kafka.js
â”‚   â”‚   â””â”€â”€ repositories/
â”‚   â”‚       â””â”€â”€ userLog.repository.js
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ userLog.services.js
â”‚   â””â”€â”€ presentation/
â”‚       â”œâ”€â”€ controllers/
â”‚       â”‚   â””â”€â”€ userLog.controller.js
â”‚       â””â”€â”€ routes/
â”‚           â””â”€â”€ userLog.route.js
â”œâ”€â”€ index.js                  # App entrypoint
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md


ğŸ” Environment Variables
PORT=5000
MONGO_URI=mongodb://mongodb:27017/log-service
KAFKA_BROKER=kafka:9092
When running locally (without Docker)
PORT=5000
MONGO_URI=mongodb://127.0.0.1:27017/log-service
KAFKA_BROKER=localhost:9092
Create a .env file in the root if you prefer
PORT=5000
MONGO_URI=mongodb://127.0.0.1:27017/log-service
KAFKA_BROKER=localhost:9092



ğŸš€ Run Locally (without Docker)
npm start

http://localhost:5000
ğŸ³ Run with Docker Compose
docker-compose up --build
â˜¸ï¸ Run on Kubernetes (Minikube)
docker build -t your-docker-username/kafka-api:latest .
docker push your-docker-username/kafka-api:latest
Apply Kubernetes manifests:
kubectl apply -f k8s/zookeeper.yaml
kubectl apply -f k8s/kafka.yaml
kubectl apply -f k8s/mongo.yaml
kubectl apply -f k8s/log-api.yaml




ğŸ“¡ REST API
POST /log/create
Content-Type: application/json

{
  "userId": "user123",
  "action": "login",
  "metadata": {
    "browser": "chrome",
    "time": 17666644441
  }
}

Response (201)
{
  "message": "Log created successfully",
  "data": {
    "_id": "....",
    "userId": "user123",
    "action": "login",
    "metadata": {
      "browser": "chrome",
      "time": 17666644441
    },
    "createdAt": "2025-11-21T12:08:37.026Z",
    "updatedAt": "2025-11-21T12:08:37.026Z"
  }
}
2ï¸âƒ£ Get Logs (with pagination & filters)
GET /log
//////////////////////////
ğŸ§ª How to Test the Flow
Use Postman or curl to send POST /log/create and GET /log requests.

Use MongoDB Compass or mongosh to inspect the log-service.userlogs collection.

Check container logs for messages like:

Message sent to Kafka: ...

Received log from Kafka: ...

Log saved to Mongo with id: ...
ğŸ— Design & Architecture Notes
Event-driven: Kafka decouples the API from the processing pipeline.

MongoDB: Flexible document-based storage for log data.

Layered architecture: Controllers â†’ Services â†’ Repositories â†’ Infrastructure.

Cloud-ready: Docker + K8s manifests make it easy to deploy on any cloud / free tier.
ğŸ¥ Demo
Starting the stack (Docker/K8s).

Sending requests to POST /log/create and GET /log.

Seeing data persisted in MongoDB.

A quick walkthrough of the architecture and main files.
